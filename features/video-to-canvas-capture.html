<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Video → Canvas Capture</title>
  <style>
    * { box-sizing: border-box; }
    body {
      font-family: system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, sans-serif;
      line-height: 1.4;
      margin: 16px;
      color: #111;
    }
    code, pre, textarea {
      font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
    }
    .row {
      display: flex;
      flex-wrap: wrap;
      gap: 16px;
      align-items: flex-start;
    }
    .col {
      flex: 1 1 360px;
      min-width: 320px;
    }
    .panel {
      border: 1px solid #ddd;
      border-radius: 8px;
      padding: 12px;
    }
    video, canvas {
      width: 100%;
      max-width: 640px;
      background: #000;
      border-radius: 8px;
      border: 1px solid #ddd;
    }
    .controls {
      display: grid;
      grid-template-columns: 1fr;
      gap: 10px;
      margin: 8px 0 0;
    }
    .controls > div {
      display: grid;
      grid-template-columns: 160px 1fr;
      gap: 10px;
      align-items: center;
    }
    input[type="text"] {
      width: 100%;
      padding: 6px 8px;
      min-width: 0;
    }
    button {
      padding: 8px 10px;
      cursor: pointer;
    }
    .buttons {
      display: flex;
      flex-wrap: wrap;
      gap: 8px;
      margin-top: 8px;
      align-items: center;
    }
    .status {
      display: grid;
      grid-template-columns: 160px 1fr;
      gap: 10px;
      align-items: baseline;
      margin-top: 8px;
    }
    .status strong {
      font-weight: 650;
    }
    pre {
      white-space: pre-wrap;
      word-break: break-word;
      background: #fafafa;
      border: 1px solid #eee;
      border-radius: 8px;
      padding: 10px;
      min-height: 140px;
      max-height: 260px;
      overflow: auto;
    }
    .pill {
      display: inline-block;
      padding: 2px 8px;
      border-radius: 999px;
      background: #f3f4f6;
      border: 1px solid #e5e7eb;
      font-size: 12px;
    }

    @media (max-width: 480px) {
      .col {
        min-width: 0;
      }
      .controls > div,
      .status {
        grid-template-columns: 1fr;
      }
      .buttons {
        gap: 10px;
      }
    }
  </style>
</head>
<body>
  <p><a href="../index.html">[Home]</a></p>

  <h1>Video → Canvas Capture</h1>

  <p><strong>Goal:</strong> verify that a playing <code>&lt;video&gt;</code> can be rendered into a <code>&lt;canvas&gt;</code> (via <code>drawImage(video, ...)</code>), and that the resulting canvas output is capturable (via <code>canvas.captureStream()</code>).</p>

  <p><strong>Expected behavior:</strong></p>
  <ul>
    <li>When the source video is playing, the canvas shows the moving video (not a black/blank frame).</li>
    <li>The “Canvas capture preview” (a <code>&lt;video&gt;</code> fed by <code>canvas.captureStream()</code>) shows the same moving content.</li>
    <li>No exceptions like <code>SecurityError</code> / “tainted canvas” when sampling pixels (if you use the default CORS-friendly source, the camera, or a local file).</li>
  </ul>

  <p>
    <strong>Autoplay mode:</strong>
    add <a href="?autoplay=1"><code>?autoplay=1</code></a> to attempt to start playback automatically (muted). Optionally also auto-start draw/capture with
    <a href="?autoplay=1&autodraw=1"><code>&amp;autodraw=1</code></a> and <a href="?autoplay=1&autocapture=1"><code>&amp;autocapture=1</code></a>.
    Use <code>0</code>/<code>false</code> to disable.
  </p>
  <p>
    <strong>Scripted play mode (no autoplay):</strong>
    add <a href="?scriptplay=1"><code>?scriptplay=1</code></a> to call <code>video.play()</code> programmatically from user gestures (Load button / file picker / “Scripted play()”)
    without doing any automatic play attempts on page load.
  </p>
  <p><strong>Presets:</strong>
    <a href="?autoplay=1"><code>?autoplay=1</code></a>,
    <a href="?autoplay=1&autodraw=1&autocapture=1"><code>?autoplay=1&amp;autodraw=1&amp;autocapture=1</code></a>,
    <a href="?scriptplay=1"><code>?scriptplay=1</code></a>,
    <a href="?scriptplay=1&autodraw=1&autocapture=1"><code>?scriptplay=1&amp;autodraw=1&amp;autocapture=1</code></a>
  </p>

  <h2>Test steps</h2>
  <ol>
    <li>Pick a source: load URL, pick a local file, or start the camera.</li>
    <li>Press Play on the source video (camera should auto-play if permitted).</li>
    <li>Tap “Start drawing video → canvas”. Confirm the canvas animates.</li>
    <li>Tap “Start canvas capture preview”. Confirm the preview animates.</li>
    <li>(Optional) Tap “Record 3 seconds” and play back/download the recording.</li>
  </ol>

  <div class="row">
    <div class="col panel">
      <h2>Source video</h2>
      <video id="sourceVideo" controls playsinline></video>

      <div class="controls">
        <div>
          <label for="videoUrl">Video URL</label>
          <input id="videoUrl" type="text" spellcheck="false" value="https://cdn.jsdelivr.net/gh/mediaelement/mediaelement-files@master/big_buck_bunny.mp4">
        </div>
        <div>
          <label for="videoFile">Local file</label>
          <input id="videoFile" type="file" accept="video/*">
        </div>
        <div>
          <label>Camera</label>
          <div class="buttons" style="margin:0">
            <button id="startCameraBtn">Start camera</button>
            <button id="stopCameraBtn" disabled>Stop camera</button>
          </div>
        </div>
      </div>

      <div class="buttons">
        <button id="loadBtn">Load</button>
        <button id="toggleMuteBtn">Unmute</button>
        <button id="scriptPlayBtn">Scripted play()</button>
        <span class="pill" id="sourcePill">crossorigin=anonymous</span>
      </div>

      <div class="status">
        <strong>Video state</strong>
        <span id="videoState">Not loaded</span>
        <strong>Video metadata</strong>
        <span id="videoMeta">—</span>
      </div>
    </div>

    <div class="col panel">
      <h2>Canvas output</h2>
      <canvas id="canvas" width="640" height="360"></canvas>
      <div class="buttons">
        <button id="startDrawBtn">Start drawing video → canvas</button>
        <button id="stopDrawBtn" disabled>Stop drawing</button>
        <button id="samplePixelBtn">Sample pixel (taint check)</button>
      </div>
      <div class="status">
        <strong>Canvas draw</strong>
        <span id="drawState">Idle</span>
        <strong>Last frame signal</strong>
        <span id="frameSignal">—</span>
      </div>
    </div>

    <div class="col panel">
      <h2>Canvas capture preview</h2>
      <video id="capturePreview" controls playsinline muted></video>
      <div class="buttons">
        <button id="startCaptureBtn">Start canvas capture preview</button>
        <button id="stopCaptureBtn" disabled>Stop capture</button>
        <button id="record3sBtn">Record 3 seconds</button>
        <a id="downloadLink" href="#" download="canvas-capture.webm" style="display:none">Download recording</a>
      </div>
      <div class="status">
        <strong>Capture state</strong>
        <span id="captureState">Idle</span>
        <strong>Recorder</strong>
        <span id="recorderState">—</span>
      </div>
    </div>
  </div>

  <h2>Log</h2>
  <pre id="log"></pre>

  <script>
    const sourceVideo = document.getElementById('sourceVideo');
    const capturePreview = document.getElementById('capturePreview');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d', { alpha: false });

    const videoUrl = document.getElementById('videoUrl');
    const videoFile = document.getElementById('videoFile');

    const loadBtn = document.getElementById('loadBtn');
    const toggleMuteBtn = document.getElementById('toggleMuteBtn');
    const scriptPlayBtn = document.getElementById('scriptPlayBtn');

    const startCameraBtn = document.getElementById('startCameraBtn');
    const stopCameraBtn = document.getElementById('stopCameraBtn');

    const startDrawBtn = document.getElementById('startDrawBtn');
    const stopDrawBtn = document.getElementById('stopDrawBtn');
    const samplePixelBtn = document.getElementById('samplePixelBtn');

    const startCaptureBtn = document.getElementById('startCaptureBtn');
    const stopCaptureBtn = document.getElementById('stopCaptureBtn');
    const record3sBtn = document.getElementById('record3sBtn');
    const downloadLink = document.getElementById('downloadLink');

    const videoState = document.getElementById('videoState');
    const videoMeta = document.getElementById('videoMeta');
    const drawState = document.getElementById('drawState');
    const frameSignal = document.getElementById('frameSignal');
    const captureState = document.getElementById('captureState');
    const recorderState = document.getElementById('recorderState');
    const sourcePill = document.getElementById('sourcePill');
    const logEl = document.getElementById('log');

    let rafId = null;
    let vfcHandle = null;
    let lastSignal = null;
    let canvasStream = null;
    let recorder = null;

    let cameraStream = null;
    let fileObjectUrl = null;
    let didAttemptAutoplayForCurrentSource = false;
    let pendingAutoStartOnPlay = false;

    const params = new URLSearchParams(location.search);
    function getBoolParam(name, defaultValue = false) {
      const v = params.get(name);
      if (v === null) return defaultValue;
      const s = String(v).trim().toLowerCase();
      if (['1', 'true', 'yes', 'on'].includes(s)) return true;
      if (['0', 'false', 'no', 'off'].includes(s)) return false;
      return defaultValue;
    }

    const autoplayMode = getBoolParam('autoplay', false);
    const autoDraw = getBoolParam('autodraw', autoplayMode);
    const autoCapture = getBoolParam('autocapture', autoplayMode);
    const scriptPlayMode = getBoolParam('scriptplay', false);

    function log(...args) {
      const line = args.map(a => (typeof a === 'string' ? a : JSON.stringify(a))).join(' ');
      logEl.textContent += `${new Date().toISOString()} ${line}\n`;
      logEl.scrollTop = logEl.scrollHeight;
    }

    function setVideoState(text) {
      videoState.textContent = text;
    }

    function setDrawState(text) {
      drawState.textContent = text;
    }

    function setCaptureState(text) {
      captureState.textContent = text;
    }

    function setSourcePill(text) {
      sourcePill.textContent = text;
    }

    function markNewSourceForAutoplay() {
      didAttemptAutoplayForCurrentSource = false;
      pendingAutoStartOnPlay = autoDraw || autoCapture;
    }

    function attemptAutoplay(reason) {
      if (!autoplayMode) return;
      if (scriptPlayMode) return;
      if (didAttemptAutoplayForCurrentSource) return;
      didAttemptAutoplayForCurrentSource = true;

      // Autoplay is typically only allowed when muted.
      sourceVideo.muted = true;
      updateMuteUi();

      try {
        const p = sourceVideo.play();
        if (p && typeof p.catch === 'function') {
          p.catch((e) => {
            setVideoState('Autoplay blocked (press Play)');
            log(`Autoplay failed (${reason}):`, String(e && (e.name || e.message || e)));
          });
        }
        setVideoState('Attempting autoplay…');
        log(`Attempting autoplay (${reason})`);
      } catch (e) {
        setVideoState('Autoplay threw (press Play)');
        log(`Autoplay threw (${reason}):`, String(e && (e.name || e.message || e)));
      }
    }

    function waitForAnyEvent(target, eventNames, timeoutMs) {
      return new Promise((resolve, reject) => {
        const timer = setTimeout(() => {
          cleanup();
          reject(new Error(`Timed out waiting for ${eventNames.join(', ')}`));
        }, timeoutMs);
        const onEvent = (e) => {
          cleanup();
          resolve(e.type);
        };
        function cleanup() {
          clearTimeout(timer);
          for (const name of eventNames) target.removeEventListener(name, onEvent);
        }
        for (const name of eventNames) target.addEventListener(name, onEvent, { once: true });
      });
    }

    function mediaErrorToString(err) {
      if (!err) return 'none';
      // https://html.spec.whatwg.org/multipage/media.html#mediaerror
      switch (err.code) {
        case 1: return 'MEDIA_ERR_ABORTED';
        case 2: return 'MEDIA_ERR_NETWORK';
        case 3: return 'MEDIA_ERR_DECODE';
        case 4: return 'MEDIA_ERR_SRC_NOT_SUPPORTED';
        default: return `MEDIA_ERR_${err.code}`;
      }
    }

    async function attemptScriptPlay(reason) {
      // In scriptPlay mode we intentionally do NOT force muted=true.
      // This should exercise the same code-path as user-gesture initiated play() calls.
      try {
        const hasSource = Boolean(sourceVideo.srcObject) || Boolean(sourceVideo.currentSrc) || Boolean(sourceVideo.src);
        if (!hasSource) {
          setVideoState('No source loaded');
          log(`Scripted play() ignored (${reason}): no source`);
          return;
        }

        // If we have a URL/blob src, ensure a load has been kicked and wait briefly for readiness.
        if (!sourceVideo.srcObject) {
          if (sourceVideo.readyState === 0) sourceVideo.load();
          if (sourceVideo.readyState < 2) {
            try {
              await waitForAnyEvent(sourceVideo, ['loadeddata', 'canplay', 'canplaythrough', 'error'], 2000);
            } catch (e) {
              // Keep going; play() itself will surface the real failure.
              log(`Scripted play() pre-wait (${reason}) failed:`, String(e && (e.message || e)));
            }
          }
        }

        setVideoState('Calling play()…');
        log(`Calling play() (${reason})`);

        const p = sourceVideo.play();
        if (p && typeof p.then === 'function') await p;
      } catch (e) {
        setVideoState('Scripted play() threw (see log)');
        log(`Scripted play() failed (${reason}):`, String(e && (e.name || e.message || e)));
        log('Video debug:', {
          readyState: sourceVideo.readyState,
          networkState: sourceVideo.networkState,
          currentSrc: sourceVideo.currentSrc,
          hasSrcObject: Boolean(sourceVideo.srcObject),
          error: mediaErrorToString(sourceVideo.error)
        });
      }
    }

    function revokeFileObjectUrlIfAny() {
      if (fileObjectUrl) {
        try { URL.revokeObjectURL(fileObjectUrl); } catch (e) { /* ignore */ }
        fileObjectUrl = null;
      }
    }

    function stopCamera() {
      if (cameraStream) {
        for (const track of cameraStream.getTracks()) track.stop();
      }
      cameraStream = null;
      stopCameraBtn.disabled = true;
      startCameraBtn.disabled = false;

      if (sourceVideo.srcObject) {
        sourceVideo.srcObject = null;
      }
    }

    async function startCamera() {
      stopDrawing();
      stopCapture();
      revokeFileObjectUrlIfAny();
      markNewSourceForAutoplay();

      downloadLink.style.display = 'none';
      downloadLink.href = '#';

      try {
        if (!navigator.mediaDevices?.getUserMedia) {
          setVideoState('getUserMedia not available');
          log('getUserMedia not available');
          return;
        }

        stopCamera();

        cameraStream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: 'user' },
          audio: false
        });

        sourceVideo.pause();
        sourceVideo.removeAttribute('src');
        sourceVideo.removeAttribute('crossorigin');
        sourceVideo.srcObject = cameraStream;

        sourceVideo.muted = true;
        updateMuteUi();

        setSourcePill('srcObject=camera');

        await sourceVideo.play();
        setVideoState('Camera started');
        updateVideoMeta();

        stopCameraBtn.disabled = false;
        startCameraBtn.disabled = true;

        log('Camera started');

        if (autoDraw && !stopDrawBtn.disabled) {
          // draw already running
        } else if (autoDraw) {
          startDrawing();
        }
        if (autoCapture && startCaptureBtn.disabled) {
          // capture already running
        } else if (autoCapture) {
          startCapture();
        }
      } catch (e) {
        stopCamera();
        setVideoState('Camera error (see log)');
        log('Camera start failed:', String(e && (e.stack || e)));
      }
    }

    function updateVideoMeta() {
      const rs = sourceVideo.readyState;
      const st = sourceVideo.currentSrc ? sourceVideo.currentSrc : (sourceVideo.srcObject ? '(srcObject)' : '(no src)');
      const dims = (sourceVideo.videoWidth && sourceVideo.videoHeight) ? `${sourceVideo.videoWidth}x${sourceVideo.videoHeight}` : '—';
      videoMeta.textContent = `readyState=${rs}, dims=${dims}`;
      log(`video src=${st}`);
      log(`video readyState=${rs}, dims=${dims}`);
    }

    function stopDrawing() {
      if (rafId !== null) {
        cancelAnimationFrame(rafId);
        rafId = null;
      }
      if (vfcHandle !== null && typeof sourceVideo.cancelVideoFrameCallback === 'function') {
        sourceVideo.cancelVideoFrameCallback(vfcHandle);
        vfcHandle = null;
      }
      setDrawState('Stopped');
      startDrawBtn.disabled = false;
      stopDrawBtn.disabled = true;
      log('Stopped drawing loop');
    }

    function drawOnce() {
      try {
        // Only attempt draw when metadata is available.
        if (sourceVideo.readyState < 2) return;

        // Draw video into canvas, scaling to fit.
        ctx.drawImage(sourceVideo, 0, 0, canvas.width, canvas.height);

        // Compute a cheap “frame signal”: sum of a few pixels. Useful for detecting frozen/black frames.
        const sample = ctx.getImageData(0, 0, 2, 2).data;
        const sum = sample[0] + sample[1] + sample[2] + sample[4] + sample[5] + sample[6];
        lastSignal = sum;
        frameSignal.textContent = `signal=${sum}`;
      } catch (e) {
        log('drawOnce error:', String(e && (e.stack || e)));
        frameSignal.textContent = `error=${String(e)}`;
        stopDrawing();
      }
    }

    function startDrawing() {
      stopDrawing();
      setDrawState('Running');
      startDrawBtn.disabled = true;
      stopDrawBtn.disabled = false;

      const useVfc = typeof sourceVideo.requestVideoFrameCallback === 'function';
      log(`Starting draw loop (requestVideoFrameCallback=${useVfc})`);

      if (useVfc) {
        const onFrame = () => {
          drawOnce();
          vfcHandle = sourceVideo.requestVideoFrameCallback(onFrame);
        };
        vfcHandle = sourceVideo.requestVideoFrameCallback(onFrame);
        return;
      }

      const loop = () => {
        drawOnce();
        rafId = requestAnimationFrame(loop);
      };
      rafId = requestAnimationFrame(loop);
    }

    function stopCapture() {
      try {
        capturePreview.pause();
      } catch (e) {
        // ignore
      }
      capturePreview.srcObject = null;
      if (canvasStream) {
        for (const t of canvasStream.getTracks()) t.stop();
      }
      canvasStream = null;
      setCaptureState('Stopped');
      startCaptureBtn.disabled = false;
      stopCaptureBtn.disabled = true;
      log('Stopped canvas capture stream');
    }

    function startCapture() {
      stopCapture();
      try {
        const fps = 30;
        canvasStream = canvas.captureStream(fps);
        capturePreview.srcObject = canvasStream;
        capturePreview.muted = true;
        capturePreview.play().catch(() => {
          // Playback might require user gesture; controls are available.
        });
        setCaptureState(`Streaming (${fps} fps requested)`);
        startCaptureBtn.disabled = true;
        stopCaptureBtn.disabled = false;

        const tracks = canvasStream.getVideoTracks();
        const settings = tracks[0] ? tracks[0].getSettings() : null;
        log('Started canvas.captureStream()', { tracks: tracks.length, settings });
      } catch (e) {
        setCaptureState(`Error: ${String(e)}`);
        log('captureStream error:', String(e && (e.stack || e)));
      }
    }

    function setSourceFromUrl(url) {
      stopDrawing();
      stopCapture();
      stopCamera();
      revokeFileObjectUrlIfAny();
      markNewSourceForAutoplay();

      downloadLink.style.display = 'none';
      downloadLink.href = '#';

      // CORS: must be set before src assignment for drawImage/getImageData to work with cross-origin media.
      sourceVideo.crossOrigin = 'anonymous';
      sourceVideo.srcObject = null;
      sourceVideo.src = url;
      sourceVideo.load();
      setSourcePill('crossorigin=anonymous');
      if (scriptPlayMode) {
        setVideoState('Loaded URL (press Scripted play() / Play)');
      } else {
        setVideoState(autoplayMode ? 'Loaded URL (attempting autoplay)' : 'Loaded URL (press Play)');
      }
      log(`Set source URL: ${url}`);

      attemptAutoplay('url');
    }

    function setSourceFromFile(file) {
      stopDrawing();
      stopCapture();
      stopCamera();
      markNewSourceForAutoplay();

      downloadLink.style.display = 'none';
      downloadLink.href = '#';

      revokeFileObjectUrlIfAny();
      fileObjectUrl = URL.createObjectURL(file);

      // For blob URLs created by this document, crossOrigin is not needed.
      sourceVideo.removeAttribute('crossorigin');
      sourceVideo.srcObject = null;
      sourceVideo.src = fileObjectUrl;
      sourceVideo.load();
      setSourcePill('src=blob:' );
      if (scriptPlayMode) {
        setVideoState(`Loaded file: ${file.name} (press Scripted play() / Play)`);
      } else {
        setVideoState(autoplayMode ? `Loaded file: ${file.name} (attempting autoplay)` : `Loaded file: ${file.name} (press Play)`);
      }
      log(`Set source file: name=${file.name}, type=${file.type}, size=${file.size}`);

      attemptAutoplay('file');
    }

    function updateMuteUi() {
      toggleMuteBtn.textContent = sourceVideo.muted ? 'Unmute' : 'Mute';
    }

    loadBtn.addEventListener('click', () => {
      const url = videoUrl.value.trim();
      if (!url) {
        log('No URL provided');
        return;
      }
      setSourceFromUrl(url);
      if (scriptPlayMode) attemptScriptPlay('loadBtn');
    });

    videoFile.addEventListener('change', () => {
      const file = videoFile.files && videoFile.files[0];
      if (!file) return;
      setSourceFromFile(file);
      if (scriptPlayMode) attemptScriptPlay('videoFile');
    });

    startCameraBtn.addEventListener('click', () => startCamera());
    stopCameraBtn.addEventListener('click', () => {
      stopCamera();
      setVideoState('Camera stopped');
      setSourcePill('—');
      updateVideoMeta();
      log('Camera stopped');
    });

    toggleMuteBtn.addEventListener('click', () => {
      sourceVideo.muted = !sourceVideo.muted;
      updateMuteUi();
    });

    scriptPlayBtn.addEventListener('click', () => attemptScriptPlay('scriptPlayBtn'));

    startDrawBtn.addEventListener('click', () => startDrawing());
    stopDrawBtn.addEventListener('click', () => stopDrawing());

    samplePixelBtn.addEventListener('click', () => {
      try {
        const d = ctx.getImageData(Math.floor(canvas.width / 2), Math.floor(canvas.height / 2), 1, 1).data;
        log(`getImageData OK: rgba(${d[0]},${d[1]},${d[2]},${d[3]})`);
      } catch (e) {
        log('getImageData failed (likely tainted canvas or draw failure):', String(e && (e.stack || e)));
      }
    });

    startCaptureBtn.addEventListener('click', () => startCapture());
    stopCaptureBtn.addEventListener('click', () => stopCapture());

    record3sBtn.addEventListener('click', async () => {
      downloadLink.style.display = 'none';
      downloadLink.href = '#';
      recorderState.textContent = '—';

      try {
        if (!canvasStream) startCapture();
        if (!canvasStream) {
          recorderState.textContent = 'No stream available';
          return;
        }

        if (typeof MediaRecorder === 'undefined') {
          recorderState.textContent = 'MediaRecorder not supported';
          log('MediaRecorder not supported in this environment');
          return;
        }

        const chunks = [];
        const options = {};

        // Prefer vp8 webm; fallback to UA defaults.
        if (MediaRecorder.isTypeSupported && MediaRecorder.isTypeSupported('video/webm;codecs=vp8')) {
          options.mimeType = 'video/webm;codecs=vp8';
        }

        recorder = new MediaRecorder(canvasStream, options);
        recorder.ondataavailable = (e) => {
          if (e.data && e.data.size) chunks.push(e.data);
        };
        recorder.onerror = (e) => {
          log('MediaRecorder error:', String(e && (e.error || e)));
        };

        const done = new Promise((resolve) => {
          recorder.onstop = resolve;
        });

        recorder.start();
        recorderState.textContent = `Recording (${recorder.mimeType || 'default'})`;
        log('MediaRecorder started', { mimeType: recorder.mimeType });

        await new Promise(r => setTimeout(r, 3000));
        recorder.stop();
        await done;

        const blob = new Blob(chunks, { type: recorder.mimeType || 'video/webm' });
        const url = URL.createObjectURL(blob);
        downloadLink.href = url;
        downloadLink.style.display = 'inline';
        recorderState.textContent = `Recorded ${Math.round(blob.size / 1024)} KiB`;
        log('MediaRecorder stopped', { bytes: blob.size });
      } catch (e) {
        recorderState.textContent = `Error: ${String(e)}`;
        log('Record failed:', String(e && (e.stack || e)));
      }
    });

    sourceVideo.addEventListener('loadedmetadata', () => {
      updateVideoMeta();
      if (!autoplayMode) {
        setVideoState('Metadata loaded (press Play)');
      } else if (sourceVideo.paused) {
        // Some engines only allow/complete autoplay after metadata is available.
        attemptAutoplay('loadedmetadata');
      }

      // Resize canvas to match video aspect ratio (keeping reasonable max width).
      if (sourceVideo.videoWidth && sourceVideo.videoHeight) {
        const maxW = 640;
        const w = Math.min(maxW, sourceVideo.videoWidth);
        const h = Math.round(w * (sourceVideo.videoHeight / sourceVideo.videoWidth));
        canvas.width = w;
        canvas.height = h;
        log(`Canvas resized to ${w}x${h}`);
      }
    });

    sourceVideo.addEventListener('error', () => {
      const err = sourceVideo.error;
      log('Video element error:', err ? `code=${err.code}` : '(unknown)');
      setVideoState('Error loading video (see log)');
    });

    sourceVideo.addEventListener('play', () => {
      setVideoState('Playing');
      updateVideoMeta();

      if (pendingAutoStartOnPlay) {
        pendingAutoStartOnPlay = false;
        if (autoDraw && startDrawBtn.disabled === false) startDrawing();
        if (autoCapture && startCaptureBtn.disabled === false) startCapture();
        if (autoDraw || autoCapture) log(`Auto-started on play (autodraw=${autoDraw}, autocapture=${autoCapture})`);
      }
    });

    sourceVideo.addEventListener('pause', () => {
      setVideoState('Paused');
    });

    // Initialize with default URL.
    updateMuteUi();
    if (scriptPlayMode) {
      loadBtn.textContent = 'Load (+ scripted play)';
      scriptPlayBtn.style.display = 'inline-block';
    } else {
      scriptPlayBtn.style.display = 'none';
    }
    setSourceFromUrl(videoUrl.value.trim());
    log('Ready');
  </script>
</body>
</html>
